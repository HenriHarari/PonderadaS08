# -*- coding: utf-8 -*-
"""ponderadaS8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LmPMIvvdHDJUDMfSTqnDhtLwYIzvHS1o
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, precision_recall_curve
import os

# Montar o Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Carregar o dataset
file_path = '/content/drive/Shareddrives/Grupo Dona Chicaca/FRAUDES.csv'
df = pd.read_csv(file_path, sep=';', on_bad_lines='skip')

# Exibir as primeiras linhas e informações do dataset
print(df.head())
print(df.info())

# Exibir as colunas para verificar os nomes corretos
print("Colunas no dataset:", df.columns)

# Escolher as colunas de características (X) e a coluna de rótulo (y)
X = df[['TIPOOS', 'ANOOS', 'SERVICO', 'STATUS', 'ATRASO']]  # Exemplos de possíveis colunas de características
y = df['FL_EXECUTADO']  # Exemplo de coluna de rótulo

# Tratar valores categóricos (convertendo colunas categóricas em representações numéricas)
X = pd.get_dummies(X)

# Garantir que os dados estão no formato float32 para X e no formato int32 para y
X = X.astype(np.float32)
y = y.astype(np.int32)

# Dividir os dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Criar um modelo de rede neural simples
def build_dense_model(input_shape):
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_shape,)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])

    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

# Inicializar o modelo
model = build_dense_model(X_train.shape[1])
model.summary()

# Treinamento com callback de early stopping
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)

# Treinamento
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[early_stopping])

# Função para visualização dos resultados de acurácia e perda
def plot_training_results(history):
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Treino')
    plt.plot(history.history['val_accuracy'], label='Validação')
    plt.title('Acurácia do Modelo')
    plt.xlabel('Época')
    plt.ylabel('Acurácia')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Treino')
    plt.plot(history.history['val_loss'], label='Validação')
    plt.title('Perda do Modelo')
    plt.xlabel('Época')
    plt.ylabel('Perda')
    plt.legend()

    plt.tight_layout()
    plt.show()

plot_training_results(history)

# Avaliação do modelo com métricas e curvas de performance
y_pred_probs = model.predict(X_test)
y_pred = np.round(y_pred_probs).flatten()

print("Relatório de Classificação:\n", classification_report(y_test, y_pred))

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Acurácia: {accuracy:.4f}")
print(f"Precisão: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-score: {f1:.4f}")

# Matriz de confusão
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title('Matriz de Confusão')
plt.ylabel('Rótulo Verdadeiro')
plt.xlabel('Rótulo Previsto')
plt.show()

# Curva ROC
fpr, tpr, _ = roc_curve(y_test, y_pred_probs)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, label=f'Curva ROC (AUC = {roc_auc:.2f})', color='darkorange')
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.title('Curva ROC')
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.legend()
plt.show()

# Curva Precision-Recall
precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred_probs)
pr_auc = auc(recall_vals, precision_vals)

plt.plot(recall_vals, precision_vals, label=f'Curva Precision-Recall (AUC = {pr_auc:.2f})', color='blue')
plt.title('Curva Precision-Recall')
plt.xlabel('Recall')
plt.ylabel('Precisão')
plt.legend()
plt.show()

# Salvar o modelo treinado
if not os.path.exists('saved_model'):
    os.makedirs('saved_model')

model.save('saved_model/tabular_model')

print("Modelo salvo com sucesso!")